defaults:
  - instruction_predictor@model: instruction_predictor_roberta
  - torch_dataset@train_dataset: basic_instruction_dataset
  - torch_dataset@dev_dataset: basic_instruction_dataset
  - evaluator: instruction_predictor_roberta_evaluator
  - _self_

train_dataset:
  data:
    filepath: data/instruction_ad/train_instruction.json
    heauristic_filter: false
    filter_with_goal: false

dev_dataset:
  data:
    filepath: data/instruction_ad/dev_instruction.json
    heauristic_filter: false
    filter_with_goal: false
  max_retries: 500
  original_prob: 0.05
  verbose: false

#model:
#  checkpoint_path: outputs/instruction_predictor/model.pkl

evaluator:
  k: 1

train:
  save_checkpoint_dir: outputs/instruction_predictor2/
  optim_state_path: null
  epochs: 50
  dataloader_workers: 0
  bsize: 16
  grad_accum_steps: 16
  log_every: 16
  eval_every: 64
  save_every: 256
  eval_bsize: 4
  eval_batches: 8
  lr: 1e-4
  roberta_lr: 1e-5
  weight_decay: 0.01
  max_steps: null
  loss: {}

wandb:
  use_wandb: true
  wandb_project: instruction_predictor_train_roberta
  log_name: null

